{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('/home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path.cwd().parent.resolve() / \"data\"\n",
    "BENCHMARK_DATA_DIR = DATA_DIR / \"benchmark\"\n",
    "\n",
    "# save image arrays in case we want to generate more features\n",
    "IMAGE_ARRAY_DIR = BENCHMARK_DATA_DIR / \"image_arrays\"\n",
    "IMAGE_ARRAY_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BENCHMARK_DATA_DIR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "    uid   region  severity    density\n0  aabm  midwest         1      585.0\n1  aacd    south         1      290.0\n2  aaee    south         1     1614.0\n3  aaff  midwest         3   111825.0\n4  aafl  midwest         4  2017313.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>midwest</td>\n      <td>1</td>\n      <td>585.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aacd</td>\n      <td>south</td>\n      <td>1</td>\n      <td>290.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aaee</td>\n      <td>south</td>\n      <td>1</td>\n      <td>1614.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaff</td>\n      <td>midwest</td>\n      <td>3</td>\n      <td>111825.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aafl</td>\n      <td>midwest</td>\n      <td>4</td>\n      <td>2017313.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(DATA_DIR / \"train_labels.csv\")\n",
    "train_labels.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      red_average  green_average  blue_average  red_median  green_median  \\\numac    26.305195      44.173160     28.357143        25.0          34.0   \negox     0.000000       0.000000      0.000000         0.0           0.0   \nhavx     0.000000       0.000000      0.000000         0.0           0.0   \nlaoq     0.000000       0.000000      0.000000         0.0           0.0   \nttsk    24.071429      41.266234     21.489177        23.0          40.0   \n\n      blue_median  \numac         27.0  \negox          0.0  \nhavx          0.0  \nlaoq          0.0  \nttsk         21.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>red_average</th>\n      <th>green_average</th>\n      <th>blue_average</th>\n      <th>red_median</th>\n      <th>green_median</th>\n      <th>blue_median</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>umac</th>\n      <td>26.305195</td>\n      <td>44.173160</td>\n      <td>28.357143</td>\n      <td>25.0</td>\n      <td>34.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>egox</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>havx</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>laoq</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>ttsk</th>\n      <td>24.071429</td>\n      <td>41.266234</td>\n      <td>21.489177</td>\n      <td>23.0</td>\n      <td>40.0</td>\n      <td>21.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features = pd.read_csv(BENCHMARK_DATA_DIR / \"image_features.csv\", index_col=0)\n",
    "image_features.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "       uid region  severity       density  red_average  green_average  \\\n2818  egox  south         2  29046.000000          0.0            0.0   \n3558  fknr   west         1    173.790293        255.0          255.0   \n4610  havx  south         1     94.000000          0.0            0.0   \n5931  jbjj  south         1   3870.000000        255.0          255.0   \n7309  laoq  south         1   2179.000000          0.0            0.0   \n\n      blue_average  red_median  green_median  blue_median       split  \n2818           0.0         0.0           0.0          0.0       train  \n3558         255.0       255.0         255.0        255.0       train  \n4610           0.0         0.0           0.0          0.0       train  \n5931         255.0       255.0         255.0        255.0       train  \n7309           0.0         0.0           0.0          0.0  validation  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>red_average</th>\n      <th>green_average</th>\n      <th>blue_average</th>\n      <th>red_median</th>\n      <th>green_median</th>\n      <th>blue_median</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2818</th>\n      <td>egox</td>\n      <td>south</td>\n      <td>2</td>\n      <td>29046.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3558</th>\n      <td>fknr</td>\n      <td>west</td>\n      <td>1</td>\n      <td>173.790293</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4610</th>\n      <td>havx</td>\n      <td>south</td>\n      <td>1</td>\n      <td>94.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>5931</th>\n      <td>jbjj</td>\n      <td>south</td>\n      <td>1</td>\n      <td>3870.000000</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>255.0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>7309</th>\n      <td>laoq</td>\n      <td>south</td>\n      <td>1</td>\n      <td>2179.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>validation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring together train labels and features into one dataframe\n",
    "# this ensures the features array and labels array will be in same order\n",
    "train_data = train_labels.merge(\n",
    "    image_features, how=\"inner\", left_on=\"uid\", right_index=True, validate=\"1:1\"\n",
    ")\n",
    "\n",
    "# split into train and validation\n",
    "rng = np.random.RandomState(30)\n",
    "train_data[\"split\"] = rng.choice(\n",
    "    [\"train\", \"validation\"], size=len(train_data), replace=True, p=[0.67, 0.33]\n",
    ")\n",
    "\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "((8, 6), (2, 6), (8,), (2,))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate features and labels, and train and validation\n",
    "feature_cols = [\n",
    "    \"red_average\",\n",
    "    \"green_average\",\n",
    "    \"blue_average\",\n",
    "    \"red_median\",\n",
    "    \"green_median\",\n",
    "    \"blue_median\",\n",
    "]\n",
    "target_col = \"severity\"\n",
    "\n",
    "val_set_mask = train_data.split == \"validation\"\n",
    "X_train = train_data.loc[~val_set_mask, feature_cols].values\n",
    "y_train = train_data.loc[~val_set_mask, target_col]\n",
    "X_val = train_data.loc[val_set_mask, feature_cols].values\n",
    "y_val = train_data.loc[val_set_mask, target_col]\n",
    "\n",
    "# flatten label data into 1-d arrays\n",
    "y_train = y_train.values.flatten()\n",
    "y_val = y_val.values.flatten()\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]: [0. 0. 0. 0. 0. 0.]\n",
      "y_train[:10]: [2 1 1 1 4 1 4 1]\n"
     ]
    }
   ],
   "source": [
    "# see an example of what the data looks like\n",
    "print(\"X_train[0]:\", X_train[0])\n",
    "print(\"y_train[:10]:\", y_train[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build LightGBM Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# save out features\n",
    "x_train_pth = BENCHMARK_DATA_DIR / \"x_train.npy\"\n",
    "x_train_pth.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with open(x_train_pth, \"wb\") as f:\n",
    "    np.save(f, X_train)\n",
    "\n",
    "# save out labels\n",
    "y_train_pth = BENCHMARK_DATA_DIR / \"y_train.npy\"\n",
    "\n",
    "with open(y_train_pth, \"wb\") as f:\n",
    "    np.save(f, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 21:48:18.537 | INFO     | __main__:<module>:28 - Loaded training features of shape (8, 6) from /home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark/x_train.npy\n",
      "2022-12-28 21:48:18.537 | INFO     | __main__:<module>:29 - Loading training labels of shape (8,) from /home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark/y_train.npy\n",
      "2022-12-28 21:48:18.538 | INFO     | __main__:<module>:35 - Fitting LGBM model\n",
      "2022-12-28 21:48:18.562 | SUCCESS  | __main__:<module>:41 - Model weights saved to /home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark/lgb_classifier.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(random_state=10)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import typer\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data/benchmark\"\n",
    "\n",
    "\n",
    "\n",
    "features_path=DATA_DIR / \"x_train.npy\"\n",
    "labels_path=DATA_DIR / \"y_train.npy\"\n",
    "model_save_path=DATA_DIR / \"lgb_classifier.txt\"\n",
    "\n",
    "\"\"\"\n",
    "Train a LightGBM model based on training features in features_path and\n",
    "training labels in labels_path. Save our the trained model to model_save_path\n",
    "\"\"\"\n",
    "\n",
    "# load saved features and labels\n",
    "with open(features_path, \"rb\") as f:\n",
    "    X_train = np.load(f)\n",
    "with open(labels_path, \"rb\") as f:\n",
    "    y_train = np.load(f)\n",
    "\n",
    "logger.info(f\"Loaded training features of shape {X_train.shape} from {features_path}\")\n",
    "logger.info(f\"Loading training labels of shape {y_train.shape} from {labels_path}\")\n",
    "\n",
    "# instantiate tree model\n",
    "model = lgb.LGBMClassifier(random_state=10)\n",
    "\n",
    "# fit model\n",
    "logger.info(\"Fitting LGBM model\")\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# save out model weights\n",
    "joblib.dump(model, str(model_save_path))\n",
    "logger.success(f\"Model weights saved to {model_save_path}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# save out validation features\n",
    "x_val_pth = BENCHMARK_DATA_DIR / \"x_val.npy\"\n",
    "x_val_pth.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "with open(x_val_pth, \"wb\") as f:\n",
    "    np.save(f, X_val)\n",
    "\n",
    "# save out validation labels\n",
    "y_val_pth = BENCHMARK_DATA_DIR / \"y_val.npy\"\n",
    "\n",
    "with open(y_val_pth, \"wb\") as f:\n",
    "    np.save(f, y_val)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 21:50:17.207 | INFO     | __main__:<module>:22 - Loaded model LGBMClassifier(random_state=10) from /home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark/lgb_classifier.txt\n",
      "2022-12-28 21:50:17.208 | INFO     | __main__:<module>:27 - Loaded features of shape (2, 6) from /home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark/x_val.npy\n",
      "2022-12-28 21:50:17.220 | SUCCESS  | __main__:<module>:35 - Predictions saved to /home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark/val_preds.npy\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "import joblib\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import typer\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data/benchmark\"\n",
    "\n",
    "\n",
    "model_weights_path=DATA_DIR / \"lgb_classifier.txt\"\n",
    "features_path=DATA_DIR / \"x_val.npy\"\n",
    "preds_save_path=DATA_DIR / \"val_preds.npy\"\n",
    "\n",
    "\"\"\"\n",
    "Generate predictions with a LightGBM model using weights saved at model_weights_path\n",
    "and features saved at features_path. Save out predictions to preds_save_path.\n",
    "\"\"\"\n",
    "# load model weights\n",
    "lgb_model = joblib.load(model_weights_path)\n",
    "logger.info(f\"Loaded model {lgb_model} from {model_weights_path}\")\n",
    "\n",
    "# load the features\n",
    "with open(features_path, \"rb\") as f:\n",
    "    X_val = np.load(f)\n",
    "logger.info(f\"Loaded features of shape {X_val.shape} from {features_path}\")\n",
    "\n",
    "# generate predictions\n",
    "preds = lgb_model.predict(X_val)\n",
    "\n",
    "# save out predictions\n",
    "with open(preds_save_path, \"wb\") as f:\n",
    "    np.save(f, preds)\n",
    "logger.success(f\"Predictions saved to {preds_save_path}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "preds_pth = BENCHMARK_DATA_DIR / \"val_preds.npy\"\n",
    "with open(preds_pth, \"rb\") as f:\n",
    "    val_preds = np.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "1    2\ndtype: int64"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(val_preds).value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "        uid region  severity  pred\n7309   laoq  south         1     1\n13003  ttsk  south         1     1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7309</th>\n      <td>laoq</td>\n      <td>south</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13003</th>\n      <td>ttsk</td>\n      <td>south</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the validation part of the training data\n",
    "val_set = train_data[train_data.split == \"validation\"][\n",
    "    [\"uid\", \"region\", \"severity\"]\n",
    "].copy()\n",
    "val_set[\"pred\"] = val_preds\n",
    "\n",
    "val_set.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for south (n=2): 0.0\n",
      "Final score: 0.0\n"
     ]
    }
   ],
   "source": [
    "region_scores = []\n",
    "for region in val_set.region.unique():\n",
    "    sub = val_set[val_set.region == region]\n",
    "    region_rmse = mean_squared_error(sub.severity, sub.pred, squared=False)\n",
    "    print(f\"RMSE for {region} (n={len(sub)}): {round(region_rmse, 4)}\")\n",
    "    region_scores.append(region_rmse)\n",
    "\n",
    "overall_rmse = np.mean(region_scores)\n",
    "print(f\"Final score: {overall_rmse}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's our RMSE across all validation data points?\n",
    "mean_squared_error(y_val, val_preds, squared=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                      predicted  actual\nseverity_level_count                   \n1                             2       2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicted</th>\n      <th>actual</th>\n    </tr>\n    <tr>\n      <th>severity_level_count</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many times did each severity level show up in our predictions vs. the actual values?\n",
    "val_results = pd.DataFrame({\"pred\": val_preds, \"actual\": y_val})\n",
    "\n",
    "pd.concat(\n",
    "    [\n",
    "        val_results.pred.value_counts().sort_index().rename(\"predicted\"),\n",
    "        val_results.actual.value_counts().sort_index().rename(\"actual\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").rename_axis(\"severity_level_count\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
