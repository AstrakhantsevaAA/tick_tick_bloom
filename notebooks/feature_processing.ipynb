{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"import cv2\\nfrom datetime import timedelta\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport odc.stac\\nimport pandas as pd\\nfrom pathlib import Path\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tqdm import tqdm\\nfrom src.data_utils.image_processing import crop_sentinel_image, crop_landsat_image, get_date_range, get_bounding_box, image_to_features, select_best_item\\n\\n%matplotlib inline\";\n                var nbb_formatted_code = \"import cv2\\nfrom datetime import timedelta\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport odc.stac\\nimport pandas as pd\\nfrom pathlib import Path\\nfrom sklearn.metrics import mean_squared_error\\nfrom sklearn.preprocessing import StandardScaler\\nfrom tqdm import tqdm\\nfrom src.data_utils.image_processing import (\\n    crop_sentinel_image,\\n    crop_landsat_image,\\n    get_date_range,\\n    get_bounding_box,\\n    image_to_features,\\n    select_best_item,\\n)\\n\\n%matplotlib inline\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import odc.stac\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from src.data_utils.image_processing import crop_sentinel_image, crop_landsat_image, get_date_range, get_bounding_box, image_to_features, select_best_item\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# Establish a connection to the STAC API\\nimport planetary_computer as pc\\nfrom pystac_client import Client\\n\\ncatalog = Client.open(\\n    \\\"https://planetarycomputer.microsoft.com/api/stac/v1\\\", modifier=pc.sign_inplace\\n)\";\n                var nbb_formatted_code = \"# Establish a connection to the STAC API\\nimport planetary_computer as pc\\nfrom pystac_client import Client\\n\\ncatalog = Client.open(\\n    \\\"https://planetarycomputer.microsoft.com/api/stac/v1\\\", modifier=pc.sign_inplace\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish a connection to the STAC API\n",
    "import planetary_computer as pc\n",
    "from pystac_client import Client\n",
    "\n",
    "catalog = Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=pc.sign_inplace\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"DATA_DIR = Path.cwd().parent.resolve() / \\\"data\\\"\\nassert DATA_DIR.exists(), DATA_DIR\";\n                var nbb_formatted_code = \"DATA_DIR = Path.cwd().parent.resolve() / \\\"data\\\"\\nassert DATA_DIR.exists(), DATA_DIR\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_DIR = Path.cwd().parent.resolve() / \"data\"\n",
    "assert DATA_DIR.exists(), DATA_DIR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    uid   latitude   longitude        date  split\n0  aabm  39.080319  -86.430867  2018-05-14  train\n1  aabn  36.559700 -121.510000  2016-08-31   test\n2  aacd  35.875083  -78.878434  2020-11-19  train\n3  aaee  35.487000  -79.062133  2016-08-24  train\n4  aaff  38.049471  -99.827001  2019-07-23  train",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aabn</td>\n      <td>36.559700</td>\n      <td>-121.510000</td>\n      <td>2016-08-31</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"metadata = pd.read_csv(DATA_DIR / \\\"metadata.csv\\\")\\nmetadata.head()\";\n                var nbb_formatted_code = \"metadata = pd.read_csv(DATA_DIR / \\\"metadata.csv\\\")\\nmetadata.head()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = pd.read_csv(DATA_DIR / \"metadata.csv\")\n",
    "metadata.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('/home/alenaastrakhantseva/PycharmProjects/tick_tick_bloom/data/benchmark')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"BENCHMARK_DATA_DIR = DATA_DIR / \\\"benchmark\\\"\\n\\n# save image arrays in case we want to generate more features\\nIMAGE_ARRAY_DIR = BENCHMARK_DATA_DIR / \\\"image_arrays\\\"\\nIMAGE_ARRAY_DIR.mkdir(exist_ok=True, parents=True)\\nBENCHMARK_DATA_DIR\";\n                var nbb_formatted_code = \"BENCHMARK_DATA_DIR = DATA_DIR / \\\"benchmark\\\"\\n\\n# save image arrays in case we want to generate more features\\nIMAGE_ARRAY_DIR = BENCHMARK_DATA_DIR / \\\"image_arrays\\\"\\nIMAGE_ARRAY_DIR.mkdir(exist_ok=True, parents=True)\\nBENCHMARK_DATA_DIR\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BENCHMARK_DATA_DIR = DATA_DIR / \"benchmark\"\n",
    "\n",
    "# save image arrays in case we want to generate more features\n",
    "IMAGE_ARRAY_DIR = BENCHMARK_DATA_DIR / \"image_arrays\"\n",
    "IMAGE_ARRAY_DIR.mkdir(exist_ok=True, parents=True)\n",
    "BENCHMARK_DATA_DIR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "train    17060\ntest      6510\nName: split, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# take a random subset of the training data for the benchmark\\ntrain_subset = metadata[metadata[\\\"split\\\"] == \\\"train\\\"]\\n\\n# combine train subset with all test data\\nmetadata_subset = pd.concat([train_subset, metadata[metadata[\\\"split\\\"] == \\\"test\\\"]])\\nmetadata_subset.split.value_counts(dropna=False)\";\n                var nbb_formatted_code = \"# take a random subset of the training data for the benchmark\\ntrain_subset = metadata[metadata[\\\"split\\\"] == \\\"train\\\"]\\n\\n# combine train subset with all test data\\nmetadata_subset = pd.concat([train_subset, metadata[metadata[\\\"split\\\"] == \\\"test\\\"]])\\nmetadata_subset.split.value_counts(dropna=False)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a random subset of the training data for the benchmark\n",
    "train_subset = metadata[metadata[\"split\"] == \"train\"]\n",
    "\n",
    "# combine train subset with all test data\n",
    "metadata_subset = pd.concat([train_subset, metadata[metadata[\"split\"] == \"test\"]])\n",
    "metadata_subset.split.value_counts(dropna=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 243/23570 [02:56<4:10:56,  1.55it/s]"
     ]
    }
   ],
   "source": [
    "# this cell takes a LONG time because it iterates over all data!\n",
    "\n",
    "# save outputs in dictionaries\n",
    "selected_items = {}\n",
    "features_dict = {}\n",
    "errored_ids = []\n",
    "\n",
    "\n",
    "for row in tqdm(metadata_subset.itertuples(), total=len(metadata_subset)):\n",
    "    pass\n",
    "    # check if we've already saved the selected image array\n",
    "    image_array_pth = IMAGE_ARRAY_DIR / f\"{row.uid}.npy\"\n",
    "\n",
    "    if image_array_pth.exists():\n",
    "        with open(image_array_pth, \"rb\") as f:\n",
    "            image_array = np.load(f)\n",
    "\n",
    "        # convert image to 1-dimensional features\n",
    "        image_features = image_to_features(image_array)\n",
    "        features_dict[row.uid] = image_features\n",
    "\n",
    "    # search and load the image array if not\n",
    "    else:\n",
    "        try:\n",
    "            ## QUERY STAC API\n",
    "            # get query ranges for location and date\n",
    "            search_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=50000\n",
    "            )\n",
    "            date_range = get_date_range(row.date, time_buffer_days=15)\n",
    "\n",
    "            # search the planetary computer\n",
    "            search = catalog.search(\n",
    "                collections=[\"sentinel-2-l2a\", \"landsat-c2-l2\"],\n",
    "                bbox=search_bbox,\n",
    "                datetime=date_range,\n",
    "            )\n",
    "            items = [item for item in search.get_all_items()]\n",
    "\n",
    "            ## GET BEST IMAGE\n",
    "            if len(items) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                best_item, item_platform, item_date = select_best_item(\n",
    "                    items, row.date, row.latitude, row.longitude\n",
    "                )\n",
    "                # add to dictionary tracking best items\n",
    "                selected_items[row.uid] = {\n",
    "                    \"item_object\": best_item,\n",
    "                    \"item_platform\": item_platform,\n",
    "                    \"item_date\": item_date,\n",
    "                }\n",
    "\n",
    "            ## CONVERT TO FEATURES\n",
    "            # get small bbox just for features\n",
    "            feature_bbox = get_bounding_box(\n",
    "                row.latitude, row.longitude, meter_buffer=100\n",
    "            )\n",
    "\n",
    "            # crop the image\n",
    "            if \"sentinel\" in item_platform.lower():\n",
    "                image_array = crop_sentinel_image(best_item, feature_bbox)\n",
    "            else:\n",
    "                image_array = crop_landsat_image(best_item, feature_bbox)\n",
    "\n",
    "            # save image array so we don't have to rerun\n",
    "            with open(image_array_pth, \"wb\") as f:\n",
    "                np.save(f, image_array)\n",
    "\n",
    "            # convert image to 1-dimensional features\n",
    "            image_features = image_to_features(image_array)\n",
    "            features_dict[row.uid] = image_features\n",
    "\n",
    "        # keep track of any that ran into errors without interrupting the process\n",
    "        except:\n",
    "            errored_ids.append(row.uid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# see how many ran into errors\n",
    "print(f\"Could not pull satellite imagery for {len(errored_ids)} samples\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# bring features into a dataframe\n",
    "image_features = pd.DataFrame(features_dict).T\n",
    "image_features.columns = [\n",
    "    \"red_average\",\n",
    "    \"green_average\",\n",
    "    \"blue_average\",\n",
    "    \"red_median\",\n",
    "    \"green_median\",\n",
    "    \"blue_median\",\n",
    "]\n",
    "image_features.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save out our features!\n",
    "image_features.to_csv(BENCHMARK_DATA_DIR / \"image_features.csv\", index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
